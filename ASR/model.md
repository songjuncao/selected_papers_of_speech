## MoE
- Efficient Fine-tuning of Audio Spectrogram Transformers via Soft Mixture of Adapters
## former
- SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding
- https://github.com/SamsungLabs/SummaryMixing
