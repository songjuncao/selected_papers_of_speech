## joint
- Jointly Recognizing Speech and Singing Voices Based on Multi-Task Audio Source Separation
  - ICME 2024
## bias
- Deferred NAM: Low-latency Top-K Context Injection via Deferred Context Encoding for Non-Streaming ASR
  - Google
  - NAACL 2024
## adapter
- Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of Large Speech Models
## general
- Advanced Long-Content Speech Recognition with Factorized Neural Transducer
  - Microsoft
  - TASLP
- Extreme Encoder Output Frame Rate Reduction: Improving Computational Latencies of Large End-to-End Models
  - Google
  - ICASSP 2024
## MoE
- Efficient Fine-tuning of Audio Spectrogram Transformers via Soft Mixture of Adapters
## former
- LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units
- SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding
- https://github.com/SamsungLabs/SummaryMixing
