## general
- Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis
- Dopamine Audiobook: A Training-free MLLM Agent for Emotional and Human-like Audiobook Generation
- GOAT-TTS: LLM-based Text-To-Speech Generation Optimized via A Dual-Branch Architecture
- FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System
- Advanced Zero-Shot Text-to-Speech for Background Removal and Preservation with Controllable Masked Speech Prediction
- STTATTS: Unified Speech-To-Text And Text-To-Speech Model
- Single-stage TTS with Masked Audio Token Modeling and Semantic Knowledge Distillation
- Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization
- Learning Fine-Grained Controllability on Speech Generation via Efficient Fine-Tuning
- Attention-Constrained Inference for Robust Decoder-Only Text-to-Speech
- GLA-Grad: A Griffin-Lim Extended Waveform Generation Diffusion Model
- VoxGenesis: Unsupervised Discovery of Latent Speaker Manifold for Speech Synthesis
- On the Semantic Latent Space of Diffusion-Based Text-to-Speech Models
## LLM
- Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens
- Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis
- FELLE: Autoregressive Speech Synthesis with Token-Wise Coarse-to-Fine Flow Matching
- Towards Controllable Speech Synthesis in the Era of Large Language Models: A Survey
- Fast and High-Quality Auto-Regressive Speech Synthesis via Speculative Decoding
- Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding
- Speaking from Coarse to Fine: Improving Neural Codec Language Model via Multi-Scale Speech Coding and Generation
- ENABLING BEAM SEARCH FOR LANGUAGE MODEL-BASED TEXT-TO-SPEECH SYNTHESIS
- SSR-Speech: Towards Stable, Safe and Robust Zero-shot Text-based Speech Editing and Synthesis
- High Fidelity Text-to-Speech Via Discrete Tokens Using Token Transducer and Group Masked Language Model
  - interspeech 2024
- Phonetic Enhanced Language Modeling for Text-to-Speech Synthesis
- Llama-VITS: Enhancing TTS Synthesis with Semantic Awareness
## zero-shot
- F5R-TTS: Improving Flow Matching based Text-to-Speech with Group Relative Policy Optimization
- Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis
- F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching
- Takin: A Cohort of Superior Quality Zero-shot Speech Generation Models
- Autoregressive Speech Synthesis without Vector Quantization
- An Investigation of Noise Robustness for Flow-Matching-Based Zero-Shot TTS
- E2 TTS: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS
  - Mircosoft
- VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers
- VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment
- Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback
- ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and Zero-shot Language Style Control With Decoupled Codec
- Seed-TTS: A Family of High-Quality Versatile Speech Generation Models
- FlashSpeech: Efficient Zero-Shot Speech Synthesis
- CoVoMix: Advancing Zero-Shot Speech Generation for Human-like Multi-talker Conversations
- RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis
  - MSRA
- CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech
  - ICLR 2024
- VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild
  - https://github.com/jasonppy/VoiceCraft
- An Empirical Study of Speech Language Models for Prompt-Conditioned Speech Synthesis
- HAM-TTS: Hierarchical Acoustic Modeling for Token-Based Zero-Shot Text-to-Speech with Model and Data Scaling
- NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models
  - MSRA
- BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data
  - Amazon
- Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like
## emotion tts
- EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting
- PROEMO: Prompt-Driven Text-to-Speech Synthesis Based on Emotion and Intensity Control
- EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control
  - EMNLP 2024
- Emotional Dimension Control in Language Model-Based Text-to-Speech: Spanning a Broad Spectrum of Human Emotions
- Laugh Now Cry Later: Controlling Time-Varying Emotional States of Flow-Matching-Based Zero-Shot Text-to-Speech
- Daisy-TTS: Simulating Wider Spectrum of Emotions via Prosody Embedding Decomposition
  - MBZUAI
## voice conversion
- Convert and Speak: Zero-shot Accent Conversion with Minimum Supervision
- PolySinger: Singing-Voice to Singing-Voice Translation from English to Japanese
- Accent Conversion in Text-To-Speech Using Multi-Level VAE and Adversarial Training
- Non-autoregressive real-time Accent Conversion model with voice cloning
- Converting Anyone's Voice: End-to-End Expressive Voice Conversion with a Conditional Diffusion Model
- Phoneme Hallucinator: One-Shot Voice Conversion via Set Expansion
- VoiceShop: A Unified Speech-to-Speech Framework for Identity-Preserving Zero-Shot Voice Editing

## multi-lingual
- CrossSpeech++: Cross-lingual Speech Synthesis with Decoupled Language and Speaker Generation
- Text-Inductive Graphone-Based Language Adaptation for Low-Resource Speech Synthesis
  - TASLP
- Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data
  - Google
  - ICASSP 2024

## eval
- VERSA: A Versatile Evaluation Toolkit for Speech, Audio, and Music
- Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech
  - Nvidia
  - ICLR

## vocoder
- BiVocoder: A Bidirectional Neural Vocoder Integrating Feature Extraction and Waveform Generation
- RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction

## light & fast
- Super Monotonic Alignment Search
- FLY-TTS: Fast, Lightweight and High-Quality End-to-End Text-to-Speech Synthesis

## frontend
- On the Effectiveness of Acoustic BPE in Decoder-Only TTS

## expressive
- FleSpeech: Flexibly Controllable Speech Generation with Various Prompts
- DrawSpeech: Expressive Speech Synthesis Using Prosodic Sketches as Control Conditions
- Style-Talker: Finetuning Audio Language Model and StyleBased Text-to-Speech Model for Fast Spoken Dialogue Generation
- Contrastive Context-Speech Pretraining for Expressive Text-to-Speech Synthesis
- UniStyle: Unified Style Modeling for Speaking Style Captioning and Stylistic Speech Synthesis
- MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech Synthesis

## super resolution
- HiFi-SR: A Unified Generative Transformer-Convolutional Adversarial Network for High-Fidelity Speech Super-Resolution

## visual
- DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker Characteristics And Intelligibility
  - NAACL 2025
