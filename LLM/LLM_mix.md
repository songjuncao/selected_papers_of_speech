- On The Landscape of Spoken Language Models: A Comprehensive Survey
- ALIGNED BETTER, LISTEN BETTER FOR AUDIO-VISUAL LARGE LANGUAGE MODELS
  - ICLR 2025
- AURELIA: Test-time Reasoning Distillation in Audio-Visual LLMs
- Qwen2.5-Omni Technical Report
- Nexus-O: An Omni-Perceptive And -Interactive Model for Language, Audio, And Vision
- A Preliminary Exploration with GPT-4o Voice Mode
- Step-Audio: Unified Understanding and Generation in Intelligent Speech Interaction
- MinMo: A Multimodal Large Language Model for Seamless Voice Interaction
- OmniChat: Enhancing Spoken Dialogue Systems with Scalable Synthetic Data for Diverse Scenarios
- Next Token Prediction Towards Multimodal Intelligence: A ComprehensiveSurvey
- GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot
- Scaling Speech-Text Pre-training with Synthetic Interleaved Data
- SALMONN-omni: A Codec-free LLM for Full-duplex Speech Understanding and Generation
- WavChat: A Survey of Spoken Dialogue Models
- Mini-Omni2: Towards Open-source GPT-4o Model with Vision, Speech and Duplex
- The Evolution of Multimodal Model Architectures
- C3LLM: Conditional Multimodal Content Generation Using Large Language Models
- Unveiling Hallucination in Text, Image, Video, and Audio Foundation Models: A Comprehensive Review
- TMT: Tri-Modal Translation between Speech, Image, and Text by Processing Different Modalities as Different Languages
  - CMU
- Beyond Language Models: Byte Models are Digital World Simulators
  - MSRA
- Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing
- MM-LLMs: Recent Advances in MultiModal Large Language Models
- On the Audio Hallucinations in Large Audio-Video Language Models
