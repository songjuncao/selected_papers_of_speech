- You Only Cache Once: Decoder-Decoder Architectures for Language Models
- The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits
- MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs
